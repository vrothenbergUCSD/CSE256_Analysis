{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "squad_dataset = load_dataset(\"squad\")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "train_df = pd.DataFrame(squad_dataset['train'])\n",
    "test_df = pd.DataFrame(squad_dataset['validation'])\n",
    "\n",
    "# Initialize the LLaMA 3 model using LangChain and Ollama\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>{'text': ['Oregon'], 'answer_start': [229]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>{'text': ['Rangoon'], 'answer_start': [414]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>{'text': ['Minsk'], 'answer_start': [476]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>{'text': ['1975'], 'answer_start': [199]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>{'text': ['Kathmandu Metropolitan City'], 'ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                     title  \\\n",
       "0      5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1      5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2      5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3      5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4      5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "...                         ...                       ...   \n",
       "87594  5735d259012e2f140011a09d                 Kathmandu   \n",
       "87595  5735d259012e2f140011a09e                 Kathmandu   \n",
       "87596  5735d259012e2f140011a09f                 Kathmandu   \n",
       "87597  5735d259012e2f140011a0a0                 Kathmandu   \n",
       "87598  5735d259012e2f140011a0a1                 Kathmandu   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                                 answers  \n",
       "0      {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1      {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2      {'text': ['the Main Building'], 'answer_start'...  \n",
       "3      {'text': ['a Marian place of prayer and reflec...  \n",
       "4      {'text': ['a golden statue of the Virgin Mary'...  \n",
       "...                                                  ...  \n",
       "87594        {'text': ['Oregon'], 'answer_start': [229]}  \n",
       "87595       {'text': ['Rangoon'], 'answer_start': [414]}  \n",
       "87596         {'text': ['Minsk'], 'answer_start': [476]}  \n",
       "87597          {'text': ['1975'], 'answer_start': [199]}  \n",
       "87598  {'text': ['Kathmandu Metropolitan City'], 'ans...  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...CONTAINING LABEL...\n",
      "('You are posed with a question answering task. You are given a context '\n",
      " 'containing relevant information and a question about the content. The answer '\n",
      " 'is contained within the context. Answer the question as concisely as '\n",
      " 'possible. Do not add any extra context.\\n'\n",
      " '\\n'\n",
      " 'Context: The pound-force has a metric counterpart, less commonly used than '\n",
      " 'the newton: the kilogram-force (kgf) (sometimes kilopond), is the force '\n",
      " 'exerted by standard gravity on one kilogram of mass. The kilogram-force '\n",
      " 'leads to an alternate, but rarely used unit of mass: the metric slug '\n",
      " '(sometimes mug or hyl) is that mass that accelerates at 1 m·s−2 when '\n",
      " 'subjected to a force of 1 kgf. The kilogram-force is not a part of the '\n",
      " 'modern SI system, and is generally deprecated; however it still sees use for '\n",
      " 'some purposes as expressing aircraft weight, jet thrust, bicycle spoke '\n",
      " 'tension, torque wrench settings and engine output torque. Other arcane units '\n",
      " 'of force include the sthène, which is equivalent to 1000 N, and the kip, '\n",
      " 'which is equivalent to 1000 lbf.\\n'\n",
      " '\\n'\n",
      " 'Question: What is the seldom used force unit equal to one thousand newtons?')\n",
      "Iteration: 10570\n",
      "Correct: 89.85%\n",
      "Response: The seldom used force unit equal to one thousand newtons is the sthène.\n",
      "SQuAD Validation Accuracy: 89.85%\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    \n",
    "\n",
    "\n",
    "# Function to format the SQuAD example for question answering\n",
    "def format_example(example):\n",
    "    context = example['context']\n",
    "    question = example['question']\n",
    "    answer = example['answers']['text'][0]  # Use the first answer\n",
    "    return context, question, answer\n",
    "\n",
    "# Function to save predictions\n",
    "def save_predictions(file_path, predictions):\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Index\", \"Predicted\", \"Correct\", \"Prompt\", \"Response\"])\n",
    "        writer.writerows(predictions)\n",
    "\n",
    "# Function to load predictions\n",
    "def load_predictions(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            return [(int(row[0]), row[1], row[2], row[3], row[4]) for row in reader]\n",
    "    return []\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(dataset, file_path='squad_predictions.csv'):\n",
    "    # Load existing predictions if they exist\n",
    "    predictions = load_predictions(file_path)\n",
    "    completed_indices = {idx for idx, _, _, _, _ in predictions}\n",
    "    correct = sum(1 for _, pred, label, _, _ in predictions if pred.lower() == label.lower())\n",
    "    total = len(predictions)\n",
    "\n",
    "    for idx, example in dataset.iterrows():\n",
    "        if idx in completed_indices:\n",
    "            continue  # Skip already processed examples\n",
    "\n",
    "        context, question, label = format_example(example)\n",
    "        clear_output(wait=True)\n",
    "        prompt = f\"You are posed with a question answering task. You are given a context containing relevant information and a question about the content. The answer is contained within the context. Answer the question as concisely as possible. Do not add any extra context.\\n\\nContext: {context}\\n\\nQuestion: {question}\"\n",
    "        response = llm.invoke(prompt).strip()\n",
    "        predicted_answer = response.strip()\n",
    "\n",
    "        # Save the prediction\n",
    "        predictions.append((idx, predicted_answer, label, prompt, response))\n",
    "        save_predictions(file_path, predictions)\n",
    "\n",
    "        rouge_score = scorer.score(predicted_answer.lower(), label.lower())['rougeL'].fmeasure\n",
    "\n",
    "        if rouge_score > 0.5:\n",
    "            print('CORRECT')\n",
    "            correct += 1\n",
    "        elif label.lower() in predicted_answer.lower():\n",
    "            print('...CONTAINING LABEL...')\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        pct = (correct / total) * 100\n",
    "        pprint(prompt)\n",
    "        \n",
    "        print(f\"Iteration: {idx + 1}\")\n",
    "        print(f\"Correct: {pct:.2f}%\")\n",
    "        print(f\"Response: {response}\")\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model and print the accuracy\n",
    "accuracy = evaluate_model(test_df)\n",
    "print(f\"SQuAD Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28571428571428575"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_f1(predicted, label):\n",
    "    pred_tokens = predicted.split()\n",
    "    label_tokens = label.split()\n",
    "    \n",
    "    common = set(pred_tokens) & set(label_tokens)\n",
    "    if len(common) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common) / len(pred_tokens)\n",
    "    rec = len(common) / len(label_tokens)\n",
    "    \n",
    "    if prec + rec == 0:\n",
    "        return 0\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "predicted = \"The Tower of Babel\"\n",
    "label = \"tower of babel\"\n",
    "calculate_f1(predicted, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (3.8.1)\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from rouge-score) (1.26.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/vince/miniforge3/envs/cse251u/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=655a9ba19682e1b92a30f33945c5b29fbd6ae6ddaf03603c306f81a7a1dd38cf\n",
      "  Stored in directory: /Users/vince/Library/Caches/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.1.0 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7272727272727273, 0.41113361690051975)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_scores(predicted, label):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    rouge_score = scorer.score(label, predicted)['rougeL'].fmeasure\n",
    "    \n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    bleu_score = sentence_bleu([label.split()], predicted.split(), smoothing_function=smoothing_function)\n",
    "    \n",
    "    return rouge_score, bleu_score\n",
    "\n",
    "predicted = \"The answer is: The Tower of Babel\"\n",
    "label = \"The Tower of Babel\"\n",
    "calculate_scores(predicted, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_df.iloc[0].answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0].context[515:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Carolina Panthers.</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Carolina Panthers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gold.</td>\n",
       "      <td>gold</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Gold.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>10565</td>\n",
       "      <td>The kilogram-force (kgf).</td>\n",
       "      <td>kilogram-force</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The kilogram-force (kgf).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>10566</td>\n",
       "      <td>The kilogram-force is sometimes referred to as...</td>\n",
       "      <td>kilopond</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The kilogram-force is sometimes referred to as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>10567</td>\n",
       "      <td>The metric slug.</td>\n",
       "      <td>slug</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The metric slug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>10568</td>\n",
       "      <td>Kip.</td>\n",
       "      <td>kip</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Kip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>10569</td>\n",
       "      <td>The seldom used force unit equal to one thousa...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The seldom used force unit equal to one thousa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                          Predicted  \\\n",
       "0          0                                The Denver Broncos.   \n",
       "1          1                             The Carolina Panthers.   \n",
       "2          2  Levi's Stadium in the San Francisco Bay Area a...   \n",
       "3          3                                The Denver Broncos.   \n",
       "4          4                                              Gold.   \n",
       "...      ...                                                ...   \n",
       "10565  10565                          The kilogram-force (kgf).   \n",
       "10566  10566  The kilogram-force is sometimes referred to as...   \n",
       "10567  10567                                   The metric slug.   \n",
       "10568  10568                                               Kip.   \n",
       "10569  10569  The seldom used force unit equal to one thousa...   \n",
       "\n",
       "                       Correct  \\\n",
       "0               Denver Broncos   \n",
       "1            Carolina Panthers   \n",
       "2      Santa Clara, California   \n",
       "3               Denver Broncos   \n",
       "4                         gold   \n",
       "...                        ...   \n",
       "10565           kilogram-force   \n",
       "10566                 kilopond   \n",
       "10567                     slug   \n",
       "10568                      kip   \n",
       "10569                   sthène   \n",
       "\n",
       "                                                  Prompt  \\\n",
       "0      You are posed with a question answering task. ...   \n",
       "1      You are posed with a question answering task. ...   \n",
       "2      You are posed with a question answering task. ...   \n",
       "3      You are posed with a question answering task. ...   \n",
       "4      You are posed with a question answering task. ...   \n",
       "...                                                  ...   \n",
       "10565  You are posed with a question answering task. ...   \n",
       "10566  You are posed with a question answering task. ...   \n",
       "10567  You are posed with a question answering task. ...   \n",
       "10568  You are posed with a question answering task. ...   \n",
       "10569  You are posed with a question answering task. ...   \n",
       "\n",
       "                                                Response  \n",
       "0                                    The Denver Broncos.  \n",
       "1                                 The Carolina Panthers.  \n",
       "2      Levi's Stadium in the San Francisco Bay Area a...  \n",
       "3                                    The Denver Broncos.  \n",
       "4                                                  Gold.  \n",
       "...                                                  ...  \n",
       "10565                          The kilogram-force (kgf).  \n",
       "10566  The kilogram-force is sometimes referred to as...  \n",
       "10567                                   The metric slug.  \n",
       "10568                                               Kip.  \n",
       "10569  The seldom used force unit equal to one thousa...  \n",
       "\n",
       "[10570 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('squad_predictions.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Rouge_Score</th>\n",
       "      <th>Bleu_Score</th>\n",
       "      <th>Containing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.113622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Carolina Panthers.</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Carolina Panthers.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.113622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Denver Broncos.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.113622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gold.</td>\n",
       "      <td>gold</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Gold.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>10565</td>\n",
       "      <td>The kilogram-force (kgf).</td>\n",
       "      <td>kilogram-force</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The kilogram-force (kgf).</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.113622</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>10566</td>\n",
       "      <td>The kilogram-force is sometimes referred to as...</td>\n",
       "      <td>kilopond</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The kilogram-force is sometimes referred to as...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>10567</td>\n",
       "      <td>The metric slug.</td>\n",
       "      <td>slug</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The metric slug.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>10568</td>\n",
       "      <td>Kip.</td>\n",
       "      <td>kip</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Kip.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>10569</td>\n",
       "      <td>The seldom used force unit equal to one thousa...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The seldom used force unit equal to one thousa...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                          Predicted  \\\n",
       "0          0                                The Denver Broncos.   \n",
       "1          1                             The Carolina Panthers.   \n",
       "2          2  Levi's Stadium in the San Francisco Bay Area a...   \n",
       "3          3                                The Denver Broncos.   \n",
       "4          4                                              Gold.   \n",
       "...      ...                                                ...   \n",
       "10565  10565                          The kilogram-force (kgf).   \n",
       "10566  10566  The kilogram-force is sometimes referred to as...   \n",
       "10567  10567                                   The metric slug.   \n",
       "10568  10568                                               Kip.   \n",
       "10569  10569  The seldom used force unit equal to one thousa...   \n",
       "\n",
       "                       Correct  \\\n",
       "0               Denver Broncos   \n",
       "1            Carolina Panthers   \n",
       "2      Santa Clara, California   \n",
       "3               Denver Broncos   \n",
       "4                         gold   \n",
       "...                        ...   \n",
       "10565           kilogram-force   \n",
       "10566                 kilopond   \n",
       "10567                     slug   \n",
       "10568                      kip   \n",
       "10569                   sthène   \n",
       "\n",
       "                                                  Prompt  \\\n",
       "0      You are posed with a question answering task. ...   \n",
       "1      You are posed with a question answering task. ...   \n",
       "2      You are posed with a question answering task. ...   \n",
       "3      You are posed with a question answering task. ...   \n",
       "4      You are posed with a question answering task. ...   \n",
       "...                                                  ...   \n",
       "10565  You are posed with a question answering task. ...   \n",
       "10566  You are posed with a question answering task. ...   \n",
       "10567  You are posed with a question answering task. ...   \n",
       "10568  You are posed with a question answering task. ...   \n",
       "10569  You are posed with a question answering task. ...   \n",
       "\n",
       "                                                Response  Rouge_Score  \\\n",
       "0                                    The Denver Broncos.     0.800000   \n",
       "1                                 The Carolina Panthers.     0.800000   \n",
       "2      Levi's Stadium in the San Francisco Bay Area a...     0.375000   \n",
       "3                                    The Denver Broncos.     0.800000   \n",
       "4                                                  Gold.     1.000000   \n",
       "...                                                  ...          ...   \n",
       "10565                          The kilogram-force (kgf).     0.666667   \n",
       "10566  The kilogram-force is sometimes referred to as...     0.181818   \n",
       "10567                                   The metric slug.     0.500000   \n",
       "10568                                               Kip.     1.000000   \n",
       "10569  The seldom used force unit equal to one thousa...     0.250000   \n",
       "\n",
       "       Bleu_Score  Containing  \n",
       "0        0.113622         1.0  \n",
       "1        0.113622         1.0  \n",
       "2        0.036021         1.0  \n",
       "3        0.113622         1.0  \n",
       "4        0.000000         1.0  \n",
       "...           ...         ...  \n",
       "10565    0.113622         1.0  \n",
       "10566    0.000000         1.0  \n",
       "10567    0.000000         1.0  \n",
       "10568    0.000000         1.0  \n",
       "10569    0.000000         1.0  \n",
       "\n",
       "[10570 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing non-alphanumeric characters and converting to lowercase.\"\"\"\n",
    "    return re.sub(r'\\W+', '', text.lower())\n",
    "\n",
    "def calculate_scores_and_flags(row):\n",
    "    correct_answer = str(row['Correct'])\n",
    "    predicted_answer = str(row['Predicted'])\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    rouge_score = scorer.score(correct_answer.lower(), predicted_answer.lower())['rougeL'].fmeasure\n",
    "    \n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    bleu_score = sentence_bleu([correct_answer.split()], predicted_answer.split(), smoothing_function=smoothing_function)\n",
    "    \n",
    "    normalized_correct = normalize_text(correct_answer)\n",
    "    normalized_predicted = normalize_text(predicted_answer)\n",
    "    containing_flag = int(normalized_correct in normalized_predicted)\n",
    "    \n",
    "    return pd.Series([rouge_score, bleu_score, containing_flag])\n",
    "\n",
    "# Apply the function to each row to create new columns\n",
    "df[['Rouge_Score', 'Bleu_Score', 'Containing']] = df.apply(calculate_scores_and_flags, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rouge = df[(df['Rouge_Score'] < 0.5) & (df['Containing'] == 1)]\n",
    "low_rouge.to_csv('low_rouge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Rouge_Score</th>\n",
       "      <th>Bleu_Score</th>\n",
       "      <th>Containing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2016.</td>\n",
       "      <td>2015</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>2016.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Four teams.</td>\n",
       "      <td>4</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Four teams.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>The Panthers have been in the Super Bowl twice...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Panthers have been in the Super Bowl twice...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>Von Miller forced two forced fumbles in Super ...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Von Miller forced two forced fumbles in Super ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>Von Miller.</td>\n",
       "      <td>linebacker Von Miller</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Von Miller.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.090697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>10542</td>\n",
       "      <td>The matrix diagonals of the tensor.</td>\n",
       "      <td>formalism</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The matrix diagonals of the tensor.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>10543</td>\n",
       "      <td>Force.</td>\n",
       "      <td>rotational equivalent for position</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Force.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10546</th>\n",
       "      <td>10546</td>\n",
       "      <td>Centripetal force goes toward the center of th...</td>\n",
       "      <td>toward the center of the curving path</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Centripetal force goes toward the center of th...</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.392815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>10553</td>\n",
       "      <td>Mechanical energy.</td>\n",
       "      <td>net mechanical energy</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Mechanical energy.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>10555</td>\n",
       "      <td>The force is called a \"gradient\" force.</td>\n",
       "      <td>artifact</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The force is called a \"gradient\" force.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                          Predicted  \\\n",
       "21        21                                              2016.   \n",
       "43        43                                        Four teams.   \n",
       "47        47  The Panthers have been in the Super Bowl twice...   \n",
       "56        56  Von Miller forced two forced fumbles in Super ...   \n",
       "58        58                                        Von Miller.   \n",
       "...      ...                                                ...   \n",
       "10542  10542                The matrix diagonals of the tensor.   \n",
       "10543  10543                                             Force.   \n",
       "10546  10546  Centripetal force goes toward the center of th...   \n",
       "10553  10553                                 Mechanical energy.   \n",
       "10555  10555            The force is called a \"gradient\" force.   \n",
       "\n",
       "                                     Correct  \\\n",
       "21                                      2015   \n",
       "43                                         4   \n",
       "47                                         2   \n",
       "56                                         2   \n",
       "58                     linebacker Von Miller   \n",
       "...                                      ...   \n",
       "10542                              formalism   \n",
       "10543     rotational equivalent for position   \n",
       "10546  toward the center of the curving path   \n",
       "10553                  net mechanical energy   \n",
       "10555                               artifact   \n",
       "\n",
       "                                                  Prompt  \\\n",
       "21     You are posed with a question answering task. ...   \n",
       "43     You are posed with a question answering task. ...   \n",
       "47     You are posed with a question answering task. ...   \n",
       "56     You are posed with a question answering task. ...   \n",
       "58     You are posed with a question answering task. ...   \n",
       "...                                                  ...   \n",
       "10542  You are posed with a question answering task. ...   \n",
       "10543  You are posed with a question answering task. ...   \n",
       "10546  You are posed with a question answering task. ...   \n",
       "10553  You are posed with a question answering task. ...   \n",
       "10555  You are posed with a question answering task. ...   \n",
       "\n",
       "                                                Response  Rouge_Score  \\\n",
       "21                                                 2016.     0.000000   \n",
       "43                                           Four teams.     0.000000   \n",
       "47     The Panthers have been in the Super Bowl twice...     0.000000   \n",
       "56     Von Miller forced two forced fumbles in Super ...     0.000000   \n",
       "58                                           Von Miller.     0.800000   \n",
       "...                                                  ...          ...   \n",
       "10542                The matrix diagonals of the tensor.     0.000000   \n",
       "10543                                             Force.     0.000000   \n",
       "10546  Centripetal force goes toward the center of th...     0.705882   \n",
       "10553                                 Mechanical energy.     0.800000   \n",
       "10555            The force is called a \"gradient\" force.     0.000000   \n",
       "\n",
       "       Bleu_Score  Containing  \n",
       "21       0.000000         0.0  \n",
       "43       0.000000         0.0  \n",
       "47       0.000000         0.0  \n",
       "56       0.000000         0.0  \n",
       "58       0.090697         0.0  \n",
       "...           ...         ...  \n",
       "10542    0.000000         0.0  \n",
       "10543    0.000000         0.0  \n",
       "10546    0.392815         0.0  \n",
       "10553    0.000000         0.0  \n",
       "10555    0.000000         0.0  \n",
       "\n",
       "[1527 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_answers = df[df['Containing'] == 0]\n",
    "wrong_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall ROUGE Score: 0.6660 (std: 0.3371)\n",
      "Overall BLEU Score: 0.1261 (std: 0.1727)\n",
      "Accuracy: 85.55%\n",
      "Correct Predictions ROUGE Score: 0.7182 (std: 0.3127)\n",
      "Correct Predictions BLEU Score: 0.1338 (std: 0.1754)\n",
      "Incorrect Predictions ROUGE Score: 0.3566 (std: 0.3099)\n",
      "Incorrect Predictions BLEU Score: 0.0801 (std: 0.1476)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame with the necessary columns\n",
    "# Calculate the overall average and standard deviation for ROUGE and BLEU scores\n",
    "avg_rouge = df['Rouge_Score'].mean()\n",
    "std_rouge = df['Rouge_Score'].std()\n",
    "avg_bleu = df['Bleu_Score'].mean()\n",
    "std_bleu = df['Bleu_Score'].std()\n",
    "\n",
    "# Calculate the accuracy based on the Containing column\n",
    "accuracy = df['Containing'].mean() * 100  # Convert to percentage\n",
    "\n",
    "# Calculate statistics for correct predictions (Containing == 1)\n",
    "correct_df = df[df['Containing'] == 1]\n",
    "avg_rouge_correct = correct_df['Rouge_Score'].mean()\n",
    "std_rouge_correct = correct_df['Rouge_Score'].std()\n",
    "avg_bleu_correct = correct_df['Bleu_Score'].mean()\n",
    "std_bleu_correct = correct_df['Bleu_Score'].std()\n",
    "\n",
    "# Calculate statistics for incorrect predictions (Containing == 0)\n",
    "incorrect_df = df[df['Containing'] == 0]\n",
    "avg_rouge_incorrect = incorrect_df['Rouge_Score'].mean()\n",
    "std_rouge_incorrect = incorrect_df['Rouge_Score'].std()\n",
    "avg_bleu_incorrect = incorrect_df['Bleu_Score'].mean()\n",
    "std_bleu_incorrect = incorrect_df['Bleu_Score'].std()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Overall ROUGE Score: {avg_rouge:.4f} (std: {std_rouge:.4f})\")\n",
    "print(f\"Overall BLEU Score: {avg_bleu:.4f} (std: {std_bleu:.4f})\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(f\"Correct Predictions ROUGE Score: {avg_rouge_correct:.4f} (std: {std_rouge_correct:.4f})\")\n",
    "print(f\"Correct Predictions BLEU Score: {avg_bleu_correct:.4f} (std: {std_bleu_correct:.4f})\")\n",
    "\n",
    "print(f\"Incorrect Predictions ROUGE Score: {avg_rouge_incorrect:.4f} (std: {std_rouge_incorrect:.4f})\")\n",
    "print(f\"Incorrect Predictions BLEU Score: {avg_bleu_incorrect:.4f} (std: {std_bleu_incorrect:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "      <th>Rouge_Score</th>\n",
       "      <th>Bleu_Score</th>\n",
       "      <th>Containing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2016.</td>\n",
       "      <td>2015</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>2016.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Four teams.</td>\n",
       "      <td>4</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Four teams.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>The Panthers have been in the Super Bowl twice...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The Panthers have been in the Super Bowl twice...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>Von Miller forced two forced fumbles in Super ...</td>\n",
       "      <td>2</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Von Miller forced two forced fumbles in Super ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>Von Miller.</td>\n",
       "      <td>linebacker Von Miller</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Von Miller.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.090697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>10542</td>\n",
       "      <td>The matrix diagonals of the tensor.</td>\n",
       "      <td>formalism</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The matrix diagonals of the tensor.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>10543</td>\n",
       "      <td>Force.</td>\n",
       "      <td>rotational equivalent for position</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Force.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10546</th>\n",
       "      <td>10546</td>\n",
       "      <td>Centripetal force goes toward the center of th...</td>\n",
       "      <td>toward the center of the curving path</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Centripetal force goes toward the center of th...</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.392815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>10553</td>\n",
       "      <td>Mechanical energy.</td>\n",
       "      <td>net mechanical energy</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>Mechanical energy.</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>10555</td>\n",
       "      <td>The force is called a \"gradient\" force.</td>\n",
       "      <td>artifact</td>\n",
       "      <td>You are posed with a question answering task. ...</td>\n",
       "      <td>The force is called a \"gradient\" force.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                          Predicted  \\\n",
       "21        21                                              2016.   \n",
       "43        43                                        Four teams.   \n",
       "47        47  The Panthers have been in the Super Bowl twice...   \n",
       "56        56  Von Miller forced two forced fumbles in Super ...   \n",
       "58        58                                        Von Miller.   \n",
       "...      ...                                                ...   \n",
       "10542  10542                The matrix diagonals of the tensor.   \n",
       "10543  10543                                             Force.   \n",
       "10546  10546  Centripetal force goes toward the center of th...   \n",
       "10553  10553                                 Mechanical energy.   \n",
       "10555  10555            The force is called a \"gradient\" force.   \n",
       "\n",
       "                                     Correct  \\\n",
       "21                                      2015   \n",
       "43                                         4   \n",
       "47                                         2   \n",
       "56                                         2   \n",
       "58                     linebacker Von Miller   \n",
       "...                                      ...   \n",
       "10542                              formalism   \n",
       "10543     rotational equivalent for position   \n",
       "10546  toward the center of the curving path   \n",
       "10553                  net mechanical energy   \n",
       "10555                               artifact   \n",
       "\n",
       "                                                  Prompt  \\\n",
       "21     You are posed with a question answering task. ...   \n",
       "43     You are posed with a question answering task. ...   \n",
       "47     You are posed with a question answering task. ...   \n",
       "56     You are posed with a question answering task. ...   \n",
       "58     You are posed with a question answering task. ...   \n",
       "...                                                  ...   \n",
       "10542  You are posed with a question answering task. ...   \n",
       "10543  You are posed with a question answering task. ...   \n",
       "10546  You are posed with a question answering task. ...   \n",
       "10553  You are posed with a question answering task. ...   \n",
       "10555  You are posed with a question answering task. ...   \n",
       "\n",
       "                                                Response  Rouge_Score  \\\n",
       "21                                                 2016.     0.000000   \n",
       "43                                           Four teams.     0.000000   \n",
       "47     The Panthers have been in the Super Bowl twice...     0.000000   \n",
       "56     Von Miller forced two forced fumbles in Super ...     0.000000   \n",
       "58                                           Von Miller.     0.800000   \n",
       "...                                                  ...          ...   \n",
       "10542                The matrix diagonals of the tensor.     0.000000   \n",
       "10543                                             Force.     0.000000   \n",
       "10546  Centripetal force goes toward the center of th...     0.705882   \n",
       "10553                                 Mechanical energy.     0.800000   \n",
       "10555            The force is called a \"gradient\" force.     0.000000   \n",
       "\n",
       "       Bleu_Score  Containing  \n",
       "21       0.000000         0.0  \n",
       "43       0.000000         0.0  \n",
       "47       0.000000         0.0  \n",
       "56       0.000000         0.0  \n",
       "58       0.090697         0.0  \n",
       "...           ...         ...  \n",
       "10542    0.000000         0.0  \n",
       "10543    0.000000         0.0  \n",
       "10546    0.392815         0.0  \n",
       "10553    0.000000         0.0  \n",
       "10555    0.000000         0.0  \n",
       "\n",
       "[1527 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are posed with a question answering task. You are given a context containing relevant information and a question about the content. The answer is contained within the context. Answer the question as concisely as possible. Do not add any extra context.\n",
      "\n",
      "Context: Oxygen is present in the atmosphere in trace quantities in the form of carbon dioxide (CO\n",
      "2). The Earth's crustal rock is composed in large part of oxides of silicon (silica SiO\n",
      "2, as found in granite and quartz), aluminium (aluminium oxide Al\n",
      "2O\n",
      "3, in bauxite and corundum), iron (iron(III) oxide Fe\n",
      "2O\n",
      "3, in hematite and rust), and calcium carbonate (in limestone). The rest of the Earth's crust is also made of oxygen compounds, in particular various complex silicates (in silicate minerals). The Earth's mantle, of much larger mass than the crust, is largely composed of silicates of magnesium and iron.\n",
      "\n",
      "Question: Aside from oxides, what other compounds comprise a large portion of the Earth's crust?\n",
      "\n",
      "Response: Aside from oxides, carbonates (as found in calcium carbonate) comprise a large portion of the Earth's crust.\n",
      "Correct: complex silicates\n"
     ]
    }
   ],
   "source": [
    "i = 390\n",
    "print(wrong_answers.iloc[i]['Prompt'])\n",
    "print()\n",
    "print(\"Response: \" + wrong_answers.iloc[i]['Response'])\n",
    "print(\"Correct: \" + wrong_answers.iloc[i]['Correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse251u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
